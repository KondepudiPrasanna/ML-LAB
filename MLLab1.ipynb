{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KondepudiPrasanna/ML-LAB/blob/main/MLLab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Find- S Algorithm :**\n",
        "The S algorithm, also known as the Find-S algorithm, is a machine learning algorithm that seeks to find a maximally specific hypothesis based on labeled training data. It starts with the most specific hypothesis and generalizes it by incorporating positive examples. It ignores negative examples during the learning process.\n",
        "\n",
        "**Steps Involved In Find-S :**\n",
        "\n",
        "Start with the most specific hypothesis. h = {ϕ, ϕ, ϕ, ϕ, ϕ, ϕ}\n",
        "\n",
        "Take the next example and if it is negative, then no changes occur to the hypothesis.\n",
        "\n",
        "If the example is positive and we find that our initial hypothesis is too specific then we update our current hypothesis to a general condition.\n",
        "\n",
        "Keep repeating the above steps till all the training examples are complete.\n",
        "\n",
        "After we have completed all the training examples we will have the final hypothesis when can use to classify the new examples.\n",
        "\n",
        "table29-e1574249851922.png\n",
        "\n",
        "**Initial Hypothesis**: { GREEN, HARD, NO, WRINKLED }\n",
        "\n",
        "**Example 1:** { GREEN, HARD, NO, WRINKLED }\n",
        "\n",
        "Matches the hypothesis, so no change.\n",
        "**Example 2 and 3:**\n",
        "\n",
        "Negative outcomes, so the hypothesis remains unchanged.\n",
        "**Example 4:** { ORANGE, HARD, NO, WRINKLED }\n",
        "\n",
        "The color attribute doesn't match, so replace it with \"?\".\n",
        "\n",
        "New hypothesis: { ?, HARD, NO, WRINKLED }\n",
        "\n",
        "**Example 5:** { GREEN, SOFT, YES, SMOOTH }\n",
        "\n",
        "All attributes don't match, so replace all with \"?\".\n",
        "\n",
        "**New hypothesis:** { ?, ?, ?, ? }\n",
        "\n",
        "Subsequent Examples: Since the hypothesis is already fully generalized, any subsequent examples will not change it.\n",
        "\n",
        "**Final Hypothesis: **{ ?, ?, ?, ? }\n",
        "\n",
        "This final hypothesis represents the most general pattern that can be inferred from the given data. It indicates that no specific attribute values can be confidently predicted based on the examples provided.\n",
        "\n",
        "1.Implement and demonstrate the FIND-S algorithm for finding the most specific hypothesis based on a given set of training data samples. Read the training data from a .CSV file."
      ],
      "metadata": {
        "id": "H2QNpF6M0BUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Attributes used in the dataset (not directly used in the code, just for reference)\n",
        "attributes = [['Sunny', 'Rainy'],\n",
        "              ['Warm', 'Cold'],\n",
        "              ['Normal', 'High'],\n",
        "              ['Strong', 'Weak'],\n",
        "              ['Warm', 'Cool'],\n",
        "              ['Same', 'Change']]\n",
        "\n",
        "num_attributes = len(attributes)\n",
        "\n",
        "# Displaying general and specific hypotheses\n",
        "print(\"\\nThe most general hypothesis: ['?','?','?','?','?','?']\\n\")\n",
        "print(\"\\nThe most specific hypothesis: ['0','0','0','0','0','0']\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMAIKQgN0iRg",
        "outputId": "e6d2ae1f-f96b-4ee6-d9e9-258bc683f0c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The most general hypothesis: ['?','?','?','?','?','?']\n",
            "\n",
            "\n",
            "The most specific hypothesis: ['0','0','0','0','0','0']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List to store the training data\n",
        "data = []\n",
        "\n",
        "# Reading the CSV file\n",
        "print(\"\\nThe Given Training Data Set\\n\")\n",
        "with open('/content/Lab1.csv', 'r') as csvFile:\n",
        "    reader = csv.reader(csvFile)\n",
        "    for row in reader:\n",
        "        data.append(row)\n",
        "        print(row)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "EQub9ALt0tDP",
        "outputId": "1ae72f45-b4de-4daf-f840-f147161bd623"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The Given Training Data Set\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Lab1.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-23cb8b457c0c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Reading the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nThe Given Training Data Set\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Lab1.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Lab1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial hypothesis (most specific)\n",
        "print(\"\\nThe initial value of hypothesis:\")\n",
        "hypothesis = ['0'] * num_attributes\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "id": "Y7o1kS4f06hg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparing with the first training example\n",
        "for j in range(num_attributes):\n",
        "    hypothesis[j] = data[0][j]\n",
        "\n",
        "# Comparing with remaining training examples of the given data set\n",
        "print(\"\\nFind S: Finding a Maximally Specific Hypothesis\\n\")\n",
        "for i in range(len(data)):\n",
        "    if data[i][num_attributes] == 'Yes':  # Only consider positive examples\n",
        "        for j in range(num_attributes):\n",
        "            if data[i][j] != hypothesis[j]:\n",
        "                hypothesis[j] = '?'\n",
        "            else:\n",
        "                hypothesis[j] = data[i][j]\n",
        "    print(f\"For Training Example No {i + 1}, the hypothesis is {hypothesis}\")"
      ],
      "metadata": {
        "id": "_OhY2HS-1IjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nThe Maximally Specific Hypothesis for a given Training Example:\\n\")\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "id": "R100jJOa1LmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After Training Example No. 1:**\n",
        "\n",
        "The hypothesis is set to match the first positive example exactly: ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same'].\n",
        "\n",
        "**After Training Example No. 2:**\n",
        "\n",
        "The second example matches the current hypothesis, so the hypothesis remains unchanged: ['Sunny', 'Warm', '?', 'Strong', 'Warm', 'Same'].\n",
        "\n",
        "**After Training Example No. 3:**\n",
        "\n",
        "The third example causes the hypothesis to be generalized where it differs. Specifically, the values for the fifth and sixth attributes are generalized to ?: ['Sunny', 'Warm', '?', 'Strong', '?', '?'].\n",
        "\n",
        "**Final Hypothesis:**\n",
        "\n",
        "The most specific hypothesis that fits all the positive examples is ['Sunny', 'Warm', '?', 'Strong', '?', '?'].\n",
        "\n",
        "This final hypothesis covers all positive training examples by being as specific as possible while accommodating variations in the data."
      ],
      "metadata": {
        "id": "wMQPiGI11Xhu"
      }
    }
  ]
}